{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f97e7c",
   "metadata": {},
   "source": [
    "# üéì Supervised Fine-Tuning (SFT) - Complete Beginner's Tutorial\n",
    "\n",
    "## Welcome! üëã\n",
    "\n",
    "This notebook will teach you **everything you need to know** about fine-tuning large language models (LLMs) like Llama 3.\n",
    "\n",
    "By the end of this tutorial, you will understand:\n",
    "- ‚úÖ What is a pre-trained language model?\n",
    "- ‚úÖ What is fine-tuning and why do we need it?\n",
    "- ‚úÖ What is LoRA and why is it better than full fine-tuning?\n",
    "- ‚úÖ How tokenization works\n",
    "- ‚úÖ How training happens step-by-step\n",
    "- ‚úÖ What all the hyperparameters mean\n",
    "- ‚úÖ How to evaluate your model\n",
    "- ‚úÖ How to use your fine-tuned model\n",
    "\n",
    "**No machine learning experience required!** We'll explain every concept from the ground up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f520f323",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Understanding the Basics\n",
    "\n",
    "## üß† What is a Language Model?\n",
    "\n",
    "### Simple Analogy:\n",
    "Imagine you're learning to predict the next word in a sentence by reading millions of books:\n",
    "\n",
    "```\n",
    "\"The capital of Nigeria is ___\"\n",
    "‚Üí Model predicts: \"Abuja\" (because it saw this pattern many times)\n",
    "\n",
    "\"How to register a business ___\"\n",
    "‚Üí Model predicts: \"in Nigeria\" (learned from similar texts)\n",
    "```\n",
    "\n",
    "That's what a language model does! It learns patterns from text and predicts what comes next.\n",
    "\n",
    "### What is Llama 3?\n",
    "- **Llama 3**: A powerful language model made by Meta\n",
    "- **8B version**: 8 billion parameters (think: 8 billion \"weights\" that make decisions)\n",
    "- **Pre-trained**: Already learned from trillions of words from the internet\n",
    "- **General knowledge**: Knows about many topics (geography, science, history, etc.)\n",
    "- **But**: Not specialized in your specific domain (Nigerian government services)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ What is Fine-Tuning?\n",
    "\n",
    "### The Problem:\n",
    "Llama 3 is great at general knowledge, but if you ask it about specific Nigerian government services, it might not be accurate.\n",
    "\n",
    "### The Solution:\n",
    "**Fine-tuning** = Teaching the model to become an expert in your specific domain\n",
    "\n",
    "### How it works:\n",
    "1. Start with Llama 3 (general knowledge model)\n",
    "2. Show it examples from your domain (Nigerian government Q&A)\n",
    "3. Model adjusts its weights to specialize in this domain\n",
    "4. Result: A model that's great at answering Nigerian government questions\n",
    "\n",
    "### Analogy:\n",
    "```\n",
    "Pre-trained model ‚âà A medical student with 4 years of general training\n",
    "Fine-tuning ‚âà 6 months of specialization in cardiology\n",
    "Fine-tuned model ‚âà A cardiologist (general knowledge + specialization)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö° Why LoRA? (Low-Rank Adaptation)\n",
    "\n",
    "### The Problem with Full Fine-Tuning:\n",
    "- Llama 3 has **8 billion parameters** (adjustable values)\n",
    "- Training all 8B parameters takes **days** and uses **100+ GB GPU memory**\n",
    "- Very expensive! ‚ùå\n",
    "\n",
    "### What is LoRA?\n",
    "LoRA is a clever trick:\n",
    "- Instead of modifying all 8B parameters, we add **small adapter layers**\n",
    "- Only train ~42M parameters (0.5% of total)\n",
    "- Result: **Same quality but 2x faster and 60% less memory** ‚úÖ\n",
    "\n",
    "### How LoRA Works (Simplified):\n",
    "```\n",
    "Traditional: Update big matrix (8000√ó8000) - SLOW\n",
    "LoRA: Update small matrices (8000√ó16) + (16√ó8000) - FAST\n",
    "\n",
    "Combined effect is similar to updating the big matrix!\n",
    "```\n",
    "\n",
    "### Memory Savings:\n",
    "```\n",
    "Full fine-tuning: 40 GB memory\n",
    "LoRA: 16 GB memory (4x savings!)\n",
    "LoRA + 4-bit: 8 GB memory (5x savings!)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üî¢ What is 4-bit Quantization?\n",
    "\n",
    "### Problem: Model weights take lots of memory\n",
    "```\n",
    "Weight stored as: 32-bit number = 0.123456789 (32 bits = 4 bytes)\n",
    "Model with 8B parameters = 8B √ó 4 bytes = 32 GB\n",
    "```\n",
    "\n",
    "### Solution: Use smaller numbers (4-bit instead of 32-bit)\n",
    "```\n",
    "Weight stored as: 4-bit number ‚âà 0.1 (4 bits = 0.5 bytes)\n",
    "Model with 8B parameters = 8B √ó 0.5 bytes = 4 GB\n",
    "Memory savings: 8x! üéâ\n",
    "```\n",
    "\n",
    "### Why does this work?\n",
    "- Most weights don't need high precision\n",
    "- 4-bit numbers are \"close enough\" for inference\n",
    "- Minimal quality loss with slight accuracy trade-off\n",
    "- Like taking a photo in 4-bit color instead of 32-bit - you lose some gradients but image is still recognizable\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaec3ce",
   "metadata": {},
   "source": [
    "# Part 2: Understanding Tokenization\n",
    "\n",
    "## üî§ What is a Token?\n",
    "\n",
    "Language models don't understand words‚Äîthey understand **numbers**.\n",
    "\n",
    "**Tokenization** = Converting text into numbers\n",
    "\n",
    "### Example:\n",
    "```\n",
    "Text: \"Hello Nigeria\"\n",
    "       ‚Üì (tokenization)\n",
    "Tokens: [15339, 29878]  (These are just numbers!)\n",
    "```\n",
    "\n",
    "### What is a token?\n",
    "A token is typically:\n",
    "- A word: \"hello\" ‚Üí 15339\n",
    "- Part of a word: \"ing\" ‚Üí 29878 (from \"running\")\n",
    "- Punctuation: \".\" ‚Üí 29889\n",
    "- Space: \" \" ‚Üí 1 (special token)\n",
    "\n",
    "### Vocabulary:\n",
    "Llama 3 has a **vocabulary of 128,000 tokens**\n",
    "- Each token maps to a unique number (0-127,999)\n",
    "- The tokenizer has a lookup table for mapping\n",
    "\n",
    "### Tokenization Example:\n",
    "```python\n",
    "Text: \"How to register a business?\"\n",
    "Tokens: [29882, 304, 8369, 263, 12881, 29973]\n",
    "         ‚Üë     ‚Üë   ‚Üë     ‚Üë   ‚Üë      ‚Üë\n",
    "         How   to  reg   a   bus    ?\n",
    "```\n",
    "\n",
    "### Why tokenization matters for fine-tuning:\n",
    "1. Models can only process tokens, not text\n",
    "2. Longer text = more tokens = more memory\n",
    "3. This is why `MAX_SEQ_LENGTH=1024` is important (max 1024 tokens per example)\n",
    "4. Language varies: English text might tokenize differently than Yoruba\n",
    "\n",
    "### Tokens vs Words:\n",
    "```\n",
    "English sentence: \"I'm going to Nigeria\"\n",
    "Words: 5 words\n",
    "Tokens: ~8 tokens (contractions and punctuation create extra tokens)\n",
    "\n",
    "Rule of thumb: 1 token ‚âà 0.75 words\n",
    "1000 tokens ‚âà 750 words\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4406c",
   "metadata": {},
   "source": [
    "# Part 3: Understanding Training\n",
    "\n",
    "## üìö How Training Works\n",
    "\n",
    "### The Training Loop (Simplified):\n",
    "```\n",
    "1. Start with pre-trained Llama 3 model\n",
    "2. Take one batch of training examples (e.g., 8 Q&A pairs)\n",
    "3. Model makes predictions on these examples\n",
    "4. Calculate LOSS = how wrong the predictions are\n",
    "5. Update model weights to reduce loss\n",
    "6. Repeat 60 times (or more for larger training)\n",
    "7. Model gets better at answering questions!\n",
    "```\n",
    "\n",
    "### What is Loss?\n",
    "**Loss** measures how wrong your model's predictions are:\n",
    "```\n",
    "Example:\n",
    "Question: \"What is the capital of Nigeria?\"\n",
    "Reference answer: \"Abuja\"\n",
    "\n",
    "Model's first attempt: \"Lagos\"\n",
    "Loss = VERY HIGH (completely wrong) ‚ùå\n",
    "\n",
    "After 10 training steps:\n",
    "Model predicts: \"Abuja or Lagos\"\n",
    "Loss = MEDIUM (partially correct)\n",
    "\n",
    "After 60 training steps:\n",
    "Model predicts: \"Abuja\"\n",
    "Loss = LOW (correct!) ‚úÖ\n",
    "```\n",
    "\n",
    "### Loss Formula (Simplified):\n",
    "```\n",
    "Loss = Average difference between model predictions and correct answers\n",
    "\n",
    "Lower loss = better model\n",
    "Higher loss = worse model\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ Batch Size and Gradient Accumulation\n",
    "\n",
    "### What is a Batch?\n",
    "Instead of training on one example at a time, we train on multiple examples together:\n",
    "```\n",
    "Example 1: Q: \"How to register a business?\" A: \"Complete the FIRS form...\"\n",
    "Example 2: Q: \"What is CAC?\" A: \"Corporate Affairs Commission...\"\n",
    "Example 3: Q: \"Cost of CAC registration?\" A: \"‚Ç¶50,000...\"\n",
    "           ‚Üì\n",
    "        (Batch of 3)\n",
    "```\n",
    "\n",
    "### Why batch training?\n",
    "1. **More stable learning**: Average loss across multiple examples\n",
    "2. **Faster**: GPU can process multiple examples at once\n",
    "3. **Better generalization**: Model learns from diverse examples\n",
    "\n",
    "### Batch Size Configuration:\n",
    "```python\n",
    "PER_DEVICE_BATCH_SIZE = 2        # Process 2 examples at a time\n",
    "GRADIENT_ACCUMULATION_STEPS = 4  # Accumulate for 4 batches\n",
    "\n",
    "Effective batch size = 2 √ó 4 = 8 examples before updating weights\n",
    "```\n",
    "\n",
    "### Why Gradient Accumulation?\n",
    "Your GPU might not have enough memory for batch size 8, so we:\n",
    "1. Process batch of 2 examples\n",
    "2. Calculate gradients (not weights yet)\n",
    "3. Store gradients in memory\n",
    "4. Repeat 4 times\n",
    "5. Add up all gradients\n",
    "6. Update weights once\n",
    "\n",
    "**Result**: Same effect as batch size 8, but uses 4x less memory!\n",
    "\n",
    "### Memory vs Speed Trade-off:\n",
    "```\n",
    "Large batch size (32):   Fast ‚ö° but needs more memory üíæ\n",
    "Small batch size (2):    Slow üê¢ but uses less memory üíæ\n",
    "With accumulation (2√ó4): Medium speed ‚ö° and memory üíæ\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéõÔ∏è Understanding Learning Rate\n",
    "\n",
    "### What is Learning Rate?\n",
    "**Learning rate** = How big a step to take when updating weights\n",
    "\n",
    "### Analogy: Finding the bottom of a valley\n",
    "```\n",
    "Too high learning rate (LR = 0.1):     Too low learning rate (LR = 0.00001):\n",
    "      ^                                  ^    \n",
    "      |  ‚ÜóÔ∏è  ‚ÜôÔ∏è  ‚ÜóÔ∏è                     |       ... ... ...\n",
    "      |  (jumps too far)                 |   (takes forever)\n",
    "      |                                  |\n",
    "    Result: Diverges, never finds bottom   Result: Finds bottom but takes ages\n",
    "\n",
    "Just right learning rate (LR = 0.0002):  \n",
    "      ^    \n",
    "      |  \\‚Üí ‚Üí ‚Üí ‚úì\n",
    "      |  (smooth descent to bottom)\n",
    "      |\n",
    "    Result: Converges smoothly to good solution\n",
    "```\n",
    "\n",
    "### Learning Rate Schedule:\n",
    "```python\n",
    "LEARNING_RATE = 2e-4  # Start at 0.0002\n",
    "WARMUP_STEPS = 5      # Gradually increase for first 5 steps\n",
    "```\n",
    "\n",
    "Why warmup?\n",
    "- Model is randomly initialized and unstable\n",
    "- Start with small LR, gradually increase to 2e-4\n",
    "- Helps training stabilize faster\n",
    "\n",
    "### Common Learning Rates:\n",
    "```\n",
    "Fine-tuning: 2e-4 to 5e-5 (small, because model already trained)\n",
    "Pre-training: 1e-3 to 3e-4 (larger, training from scratch)\n",
    "Classification: 1e-3 to 1e-4 (varies by dataset size)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f437a16",
   "metadata": {},
   "source": [
    "# Part 4: Understanding Hyperparameters\n",
    "\n",
    "## üìä Complete Hyperparameter Breakdown\n",
    "\n",
    "### Model Architecture Parameters:\n",
    "\n",
    "```python\n",
    "MODEL_NAME = \"unsloth/llama-3.1-8b-Instruct-bnb-4bit\"\n",
    "# ‚îú‚îÄ \"unsloth\": Optimized version for faster training\n",
    "# ‚îú‚îÄ \"llama-3.1\": Model type\n",
    "# ‚îú‚îÄ \"8b\": 8 billion parameters\n",
    "# ‚îú‚îÄ \"Instruct\": Fine-tuned for following instructions\n",
    "# ‚îî‚îÄ \"bnb-4bit\": Uses 4-bit quantization\n",
    "\n",
    "MAX_SEQ_LENGTH = 1024\n",
    "# Maximum tokens in one training example\n",
    "# If example is longer, it gets truncated\n",
    "# If shorter, it gets padded (filled with special tokens)\n",
    "# ~750 words ‚âà 1000 tokens (rule: 1 token ‚âà 0.75 words)\n",
    "# Larger = better but uses more memory\n",
    "\n",
    "LOAD_IN_4BIT = True\n",
    "# Load model in 4-bit precision\n",
    "# 8x memory savings with minimal quality loss\n",
    "```\n",
    "\n",
    "### LoRA Parameters:\n",
    "\n",
    "```python\n",
    "LORA_R = 16\n",
    "# Rank of LoRA adapters\n",
    "# Higher R = more parameters to train, better quality but slower\n",
    "# Common values: 8, 16, 32, 64\n",
    "# For small datasets: 8-16\n",
    "# For large datasets: 32-64\n",
    "\n",
    "LORA_ALPHA = 16\n",
    "# Scaling factor for LoRA updates\n",
    "# Usually set equal to LORA_R\n",
    "# Affects how much LoRA contributes to final model\n",
    "# Effective scaling = LORA_ALPHA / LORA_R = 1.0 (neutral)\n",
    "\n",
    "LORA_DROPOUT = 0\n",
    "# Regularization: randomly drops out connections during training\n",
    "# 0 = no dropout\n",
    "# 0.05 = drop 5% of connections (prevents overfitting)\n",
    "# For small datasets, use 0.05 to prevent overfitting\n",
    "# For large datasets, can use 0 to train faster\n",
    "```\n",
    "\n",
    "### Training Schedule Parameters:\n",
    "\n",
    "```python\n",
    "MAX_STEPS = 60\n",
    "# Maximum number of training steps\n",
    "# 1 step = 1 weight update\n",
    "# For testing: 60-200 steps\n",
    "# For real training: 500-5000 steps (depends on dataset size)\n",
    "# Formula: steps = (num_examples √ó epochs) / batch_size\n",
    "\n",
    "PER_DEVICE_BATCH_SIZE = 2\n",
    "# Examples processed per GPU before weight update\n",
    "# Larger = faster but needs more memory\n",
    "# Smaller = slower but uses less memory\n",
    "# Common: 2-8 for fine-tuning\n",
    "\n",
    "GRADIENT_ACCUMULATION_STEPS = 4\n",
    "# Accumulate gradients for N batches before updating weights\n",
    "# Effective batch = 2 √ó 4 = 8\n",
    "# Trade: GPU memory for computational efficiency\n",
    "# Higher = more memory efficient but slower convergence\n",
    "```\n",
    "\n",
    "### Optimization Parameters:\n",
    "\n",
    "```python\n",
    "LEARNING_RATE = 2e-4  (0.0002)\n",
    "# Step size for weight updates\n",
    "# Too high: Training diverges (loss increases)\n",
    "# Too low: Training is very slow\n",
    "# For fine-tuning: 1e-4 to 5e-4 is typical\n",
    "\n",
    "WARMUP_STEPS = 5\n",
    "# Gradually increase LR for first N steps\n",
    "# Helps stabilize training\n",
    "# Typical: 5-10% of total steps\n",
    "# For 60 steps: 5 warmup steps is good\n",
    "\n",
    "WEIGHT_DECAY = 0.01\n",
    "# L2 regularization to prevent overfitting\n",
    "# Adds penalty for large weights\n",
    "# Typical: 0 (none) to 0.1\n",
    "# Higher = more regularization = underfitting risk\n",
    "\n",
    "LR_SCHEDULER_TYPE = \"linear\"\n",
    "# How to adjust learning rate during training\n",
    "# Options: \"linear\", \"cosine\", \"constant\"\n",
    "# Linear: Decrease LR linearly from peak to near 0\n",
    "# Cosine: Smooth decrease following cosine curve\n",
    "# Constant: Keep LR fixed throughout\n",
    "\n",
    "OPTIM = \"adamw_8bit\"\n",
    "# Optimization algorithm (AdamW)\n",
    "# \"8bit\": Uses 8-bit precision for optimizer states\n",
    "# Saves memory without hurting convergence\n",
    "```\n",
    "\n",
    "### Precision Parameters:\n",
    "\n",
    "```python\n",
    "FP16 = True   # 16-bit floating point (older GPUs like T4)\n",
    "BF16 = False  # Brain Float 16 (newer GPUs like A100)\n",
    "# Only one should be True!\n",
    "# FP16: Good precision but can be unstable\n",
    "# BF16: More stable, better for training\n",
    "# 2x faster than FP32, half the memory\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚öôÔ∏è How to Choose Hyperparameters\n",
    "\n",
    "### For Your First Fine-Tuning:\n",
    "\n",
    "| Parameter | Value | Why? |\n",
    "|-----------|-------|------|\n",
    "| LORA_R | 8-16 | Smaller = faster for experimentation |\n",
    "| MAX_STEPS | 60-200 | Quick test to verify training works |\n",
    "| PER_DEVICE_BATCH_SIZE | 2-4 | Smaller = less memory |\n",
    "| LEARNING_RATE | 2e-4 | Safe default for fine-tuning |\n",
    "| WARMUP_STEPS | 5-10 | ~10% of total steps |\n",
    "\n",
    "### For Production:\n",
    "\n",
    "| Parameter | Value | Why? |\n",
    "|-----------|-------|------|\n",
    "| LORA_R | 32-64 | Larger = better quality |\n",
    "| MAX_STEPS | 1000-5000 | More training = better results |\n",
    "| PER_DEVICE_BATCH_SIZE | 4-8 | Larger = faster convergence |\n",
    "| LEARNING_RATE | 1e-4 to 5e-4 | Experiment and pick best |\n",
    "| WARMUP_STEPS | 100-500 | ~10% of total steps |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb13d52",
   "metadata": {},
   "source": [
    "# Part 5: Data Preparation\n",
    "\n",
    "## üìö Training Data Format\n",
    "\n",
    "### Required Format (JSON):\n",
    "```json\n",
    "[\n",
    "  {\n",
    "    \"question\": \"How do I register my business in Nigeria?\",\n",
    "    \"answer\": \"To register your business, follow these steps: 1. Go to CAC website, 2. Fill the form, 3. Pay fees, 4. Get certificate\",\n",
    "    \"agency\": \"CAC\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What is the cost of business registration?\",\n",
    "    \"answer\": \"The cost is ‚Ç¶50,000 for business registration with CAC\",\n",
    "    \"agency\": \"CAC\"\n",
    "  }\n",
    "]\n",
    "```\n",
    "\n",
    "### Why this format?\n",
    "- **question**: What the user asks\n",
    "- **answer**: The correct response (model learns to generate this)\n",
    "- **agency**: For tracking/filtering (optional)\n",
    "\n",
    "---\n",
    "\n",
    "## üîÄ Train/Validation/Test Split\n",
    "\n",
    "### Why split data?\n",
    "```\n",
    "Training set (80%):    Model learns from these examples\n",
    "                       Loss decreases as model trains\n",
    "                       ‚Üì\n",
    "Validation set (10%):  Check if model generalizes\n",
    "                       If val_loss >> train_loss ‚Üí OVERFITTING\n",
    "                       ‚Üì\n",
    "Test set (10%):        Final evaluation (never seen during training)\n",
    "                       True measure of model quality\n",
    "```\n",
    "\n",
    "### What is Overfitting?\n",
    "```\n",
    "Good model:                    Overfitted model:\n",
    "Training loss: 0.5             Training loss: 0.1 (very low)\n",
    "Validation loss: 0.52          Validation loss: 2.5 (very high)\n",
    "Test loss: 0.51                Test loss: 2.4\n",
    "‚Üí Generalizes well             ‚Üí Memorized training data\n",
    "```\n",
    "\n",
    "### How much data do you need?\n",
    "```\n",
    "100-500 examples:    Quick experiment/proof of concept\n",
    "500-2000 examples:   Small fine-tune, acceptable quality\n",
    "2000-10000:          Good fine-tune with solid results\n",
    "10000+:              Excellent fine-tune, strong specialization\n",
    "```\n",
    "\n",
    "### Data Quality Matters More Than Quantity:\n",
    "```\n",
    "500 high-quality Q&A pairs > 5000 low-quality pairs\n",
    "\n",
    "High-quality means:\n",
    "- Accurate answers\n",
    "- Clear questions\n",
    "- Diverse examples\n",
    "- Correct grammar\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd466c14",
   "metadata": {},
   "source": [
    "# Part 6: Evaluation Metrics\n",
    "\n",
    "## üìä Understanding Loss\n",
    "\n",
    "### Training Loss vs Validation Loss:\n",
    "```\n",
    "Step 1:   Training loss: 2.5, Validation loss: 2.6\n",
    "Step 30:  Training loss: 0.8, Validation loss: 0.85\n",
    "Step 60:  Training loss: 0.3, Validation loss: 0.35\n",
    "\n",
    "Good: Both decrease together\n",
    "```\n",
    "\n",
    "### Red Flags:\n",
    "```\n",
    "Training loss: 0.1, Validation loss: 5.0 ‚Üí OVERFITTING\n",
    "Training loss: 0.5, Validation loss: 0.5, but not decreasing ‚Üí NOT TRAINING\n",
    "Training loss: increases ‚Üí LEARNING RATE TOO HIGH\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üî¥ ROUGE Scores (Advanced Evaluation)\n",
    "\n",
    "### What is ROUGE?\n",
    "**ROUGE** = Recall-Oriented Understudy for Gisting Evaluation\n",
    "\n",
    "Measures overlap between model response and reference answer:\n",
    "\n",
    "```\n",
    "Reference: \"The capital of Nigeria is Abuja located in central Nigeria\"\n",
    "Response:  \"Nigeria's capital is Abuja in central Nigeria\"\n",
    "\n",
    "Matching words: capital, of, is, Abuja, located, in, Nigeria\n",
    "ROUGE Score: measures how many matching words\n",
    "```\n",
    "\n",
    "### ROUGE Types:\n",
    "\n",
    "```python\n",
    "ROUGE-1: Unigram (single word) overlap\n",
    "# Does response contain same words as reference?\n",
    "# Reference: \"Abuja is capital\"\n",
    "# Response:  \"capital is Abuja\"  \n",
    "# ROUGE-1: 3/3 = 1.0 (all words match)\n",
    "\n",
    "ROUGE-2: Bigram (two-word pairs) overlap\n",
    "# Does response contain same phrases?\n",
    "# Reference: \"Abuja is capital\"\n",
    "# Response:  \"capital is Abuja\"\n",
    "# ROUGE-2: 0/2 = 0.0 (no matching phrases)\n",
    "# (Different word order = different bigrams)\n",
    "\n",
    "ROUGE-L: Longest common subsequence\n",
    "# What's the longest matching sequence?\n",
    "# Reference: \"Abuja is capital\"\n",
    "# Response:  \"Abuja is capital\"\n",
    "# ROUGE-L: 1.0 (perfect match)\n",
    "```\n",
    "\n",
    "### Interpreting ROUGE Scores (0-1 scale):\n",
    "\n",
    "```\n",
    "ROUGE-1 > 0.4:  Good word overlap ‚úÖ\n",
    "ROUGE-1 0.2-0.4: Fair overlap ‚ö†Ô∏è\n",
    "ROUGE-1 < 0.2:  Poor overlap ‚ùå\n",
    "\n",
    "ROUGE-L > 0.3:  Good sentence similarity ‚úÖ\n",
    "ROUGE-L 0.1-0.3: Fair similarity ‚ö†Ô∏è\n",
    "ROUGE-L < 0.1:  Poor similarity ‚ùå\n",
    "```\n",
    "\n",
    "### Important Limitation:\n",
    "ROUGE only measures **surface-level overlap**, not semantic meaning:\n",
    "\n",
    "```\n",
    "Reference: \"Nigeria's capital is Abuja\"\n",
    "Response 1: \"The capital of Nigeria is Abuja\"     ‚Üí ROUGE-1: 0.80 (high)\n",
    "Response 2: \"Lagos is the largest city in Nigeria\" ‚Üí ROUGE-1: 0.33 (low)\n",
    "\n",
    "Both are reasonable answers but ROUGE scores differ significantly!\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Better Evaluation Methods\n",
    "\n",
    "### Manual Evaluation:\n",
    "Read model responses and rate quality 1-5:\n",
    "```\n",
    "1 = Completely wrong\n",
    "2 = Mostly wrong\n",
    "3 = Partially correct\n",
    "4 = Mostly correct\n",
    "5 = Perfect answer\n",
    "\n",
    "Average rating shows true quality better than ROUGE\n",
    "```\n",
    "\n",
    "### Task-Specific Metrics:\n",
    "```\n",
    "For Q&A: Did model answer the question?\n",
    "For Code: Does generated code run without errors?\n",
    "For Classification: Accuracy on held-out test set\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019abcc1",
   "metadata": {},
   "source": [
    "# Part 7: The Complete Training Workflow\n",
    "\n",
    "## üîÑ Step-by-Step Process\n",
    "\n",
    "```\n",
    "1. SETUP\n",
    "   ‚îî‚îÄ Install libraries (Unsloth, Transformers, TRL, etc.)\n",
    "   ‚îî‚îÄ Check GPU availability\n",
    "   ‚îî‚îÄ Load configuration\n",
    "   ‚Üì\n",
    "2. LOAD MODEL\n",
    "   ‚îî‚îÄ Download Llama 3 (8B model)\n",
    "   ‚îî‚îÄ Load in 4-bit quantization\n",
    "   ‚îî‚îÄ Load tokenizer\n",
    "   ‚Üì\n",
    "3. ADD LORA\n",
    "   ‚îî‚îÄ Add LoRA adapter layers\n",
    "   ‚îî‚îÄ Freeze base model weights\n",
    "   ‚îî‚îÄ Only ~42M parameters trainable (0.5% of 8B)\n",
    "   ‚Üì\n",
    "4. PREPARE DATA\n",
    "   ‚îî‚îÄ Load JSON training data\n",
    "   ‚îî‚îÄ Convert to chat format\n",
    "   ‚îî‚îÄ Split: 80% train, 10% val, 10% test\n",
    "   ‚Üì\n",
    "5. TOKENIZE\n",
    "   ‚îî‚îÄ Apply chat template\n",
    "   ‚îî‚îÄ Convert text to tokens\n",
    "   ‚îî‚îÄ Pad/truncate to MAX_SEQ_LENGTH\n",
    "   ‚Üì\n",
    "6. CONFIGURE TRAINER\n",
    "   ‚îî‚îÄ Set batch size, learning rate, steps\n",
    "   ‚îî‚îÄ Choose optimizer and scheduler\n",
    "   ‚îî‚îÄ Set up logging\n",
    "   ‚Üì\n",
    "7. TRAIN\n",
    "   ‚îî‚îÄ Feed batches to model\n",
    "   ‚îî‚îÄ Compute loss\n",
    "   ‚îî‚îÄ Update LoRA weights\n",
    "   ‚îî‚îÄ Repeat for MAX_STEPS times\n",
    "   ‚Üì\n",
    "8. EVALUATE\n",
    "   ‚îî‚îÄ Run model on validation set\n",
    "   ‚îî‚îÄ Calculate ROUGE scores on test set\n",
    "   ‚îî‚îÄ Check for overfitting\n",
    "   ‚Üì\n",
    "9. SAVE\n",
    "   ‚îî‚îÄ Save LoRA adapters (~50MB)\n",
    "   ‚îî‚îÄ Save merged model (~16GB)\n",
    "   ‚îî‚îÄ Save tokenizer\n",
    "   ‚Üì\n",
    "10. DEPLOY\n",
    "    ‚îî‚îÄ Use for inference\n",
    "    ‚îî‚îÄ Answer questions\n",
    "    ‚îî‚îÄ Or upload to Hugging Face\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcf199a",
   "metadata": {},
   "source": [
    "# Part 8: Common Issues and Debugging\n",
    "\n",
    "## ‚ö†Ô∏è Problem: Out of Memory (OOM)\n",
    "\n",
    "### Symptoms:\n",
    "```\n",
    "RuntimeError: CUDA out of memory. Tried to allocate X.XX GiB\n",
    "```\n",
    "\n",
    "### Solutions (ranked by effectiveness):\n",
    "\n",
    "```python\n",
    "1. Reduce PER_DEVICE_BATCH_SIZE:\n",
    "   2 ‚Üí 1\n",
    "   (Uses 50% less memory)\n",
    "\n",
    "2. Increase GRADIENT_ACCUMULATION_STEPS:\n",
    "   4 ‚Üí 8\n",
    "   (Accumulate for 8 batches instead of 4)\n",
    "\n",
    "3. Reduce MAX_SEQ_LENGTH:\n",
    "   1024 ‚Üí 512\n",
    "   (Shorter sequences = less memory)\n",
    "\n",
    "4. Reduce LORA_R:\n",
    "   16 ‚Üí 8\n",
    "   (Smaller adapters = less memory)\n",
    "\n",
    "5. Use packing=True:\n",
    "   (Combine short examples to be more memory efficient)\n",
    "\n",
    "6. Use gradient checkpointing:\n",
    "   (Already enabled in Unsloth by default)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Problem: Training Loss Not Decreasing\n",
    "\n",
    "### Symptoms:\n",
    "```\n",
    "Step 1:  Loss = 2.5\n",
    "Step 10: Loss = 2.5 (no change!)\n",
    "Step 30: Loss = 2.5 (still no change!)\n",
    "```\n",
    "\n",
    "### Causes and Solutions:\n",
    "\n",
    "```python\n",
    "1. Learning rate too low:\n",
    "   LR = 1e-6 (way too small)\n",
    "   Solution: Increase to 2e-4 or 5e-4\n",
    "\n",
    "2. Model not training (weights frozen?):\n",
    "   Check: Are requires_grad=True for LoRA params?\n",
    "   Solution: Verify LoRA was added correctly\n",
    "\n",
    "3. Data format wrong:\n",
    "   If all examples are identical\n",
    "   Solution: Check JSON format and data quality\n",
    "\n",
    "4. Not enough training steps:\n",
    "   MAX_STEPS = 5 (too few)\n",
    "   Solution: Increase to at least 60-100\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Problem: Loss Increasing (Diverging)\n",
    "\n",
    "### Symptoms:\n",
    "```\n",
    "Step 1:  Loss = 2.5\n",
    "Step 10: Loss = 5.0 (increasing!)\n",
    "Step 30: Loss = 10.0 (getting worse!)\n",
    "```\n",
    "\n",
    "### Causes and Solutions:\n",
    "\n",
    "```python\n",
    "1. Learning rate too high:\n",
    "   LR = 0.1 (way too high)\n",
    "   Solution: Decrease to 2e-4 or 5e-5\n",
    "\n",
    "2. Data quality issues:\n",
    "   Corrupted or invalid examples\n",
    "   Solution: Check training data format and content\n",
    "\n",
    "3. Floating point precision issues:\n",
    "   Solution: Use BF16 instead of FP16 (if GPU supports)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ‚ö†Ô∏è Problem: Model Overfitting\n",
    "\n",
    "### Symptoms:\n",
    "```\n",
    "Training loss:   0.1 (very low)\n",
    "Validation loss: 2.5 (very high)\n",
    "Test ROUGE: 0.15 (poor)\n",
    "```\n",
    "\n",
    "### Solutions:\n",
    "\n",
    "```python\n",
    "1. Add dropout:\n",
    "   LORA_DROPOUT = 0 ‚Üí 0.05\n",
    "   (Prevents overfitting)\n",
    "\n",
    "2. Increase training data:\n",
    "   More examples = model learns patterns not memorization\n",
    "\n",
    "3. Add weight decay:\n",
    "   weight_decay = 0 ‚Üí 0.01\n",
    "   (Penalizes large weights)\n",
    "\n",
    "4. Reduce LORA_R:\n",
    "   16 ‚Üí 8\n",
    "   (Fewer parameters = harder to memorize)\n",
    "\n",
    "5. Use early stopping:\n",
    "   Stop training when val_loss stops improving\n",
    "   (Don't train for MAX_STEPS if not improving)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a800f7",
   "metadata": {},
   "source": [
    "# Part 9: Advanced Concepts\n",
    "\n",
    "## üî¨ What Happens During Training (Deep Dive)\n",
    "\n",
    "### Inside One Training Step:\n",
    "\n",
    "```\n",
    "Input: Batch of 2 examples (effective batch = 8 with accumulation)\n",
    "\n",
    "Example 1:\n",
    "  Q: \"How to register business?\"\n",
    "  A: \"Complete FIRS form at CAC office...\"\n",
    "  \n",
    "Example 2:\n",
    "  Q: \"What is CAC?\"\n",
    "  A: \"Corporate Affairs Commission oversees registration...\"\n",
    "\n",
    "STEP 1: Convert to tokens\n",
    "  [\"How\", \"to\", \"register\", ...] ‚Üí [1294, 304, 8369, ...]\n",
    "  \n",
    "STEP 2: Forward pass through model\n",
    "  Tokens go through transformer layers\n",
    "  Each layer processes the sequence\n",
    "  Attention mechanisms learn relationships between words\n",
    "  Output: Predicted tokens\n",
    "  \n",
    "STEP 3: Calculate loss\n",
    "  Compare predicted tokens with ground truth\n",
    "  If correct: loss = low\n",
    "  If wrong: loss = high\n",
    "  Average loss across batch\n",
    "  \n",
    "STEP 4: Backward pass\n",
    "  Calculate how much each weight contributed to the error\n",
    "  Compute gradients (derivatives) for each parameter\n",
    "  \n",
    "STEP 5: Update weights (LoRA only!)\n",
    "  weight = weight - (learning_rate √ó gradient)\n",
    "  Only LoRA weights updated (~42M parameters)\n",
    "  Base model weights frozen\n",
    "  \n",
    "RESULT: Model slightly better at predicting answers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üß¨ How LoRA Actually Works\n",
    "\n",
    "### The Math (Simplified):\n",
    "\n",
    "```python\n",
    "# Without LoRA:\n",
    "output = W √ó input  # W is 8000√ó8000 matrix (64M parameters)\n",
    "\n",
    "# With LoRA:\n",
    "# Instead of updating W directly, we add a small update:\n",
    "W_new = W + ŒîW\n",
    "\n",
    "# ŒîW is approximated as a product of two smaller matrices:\n",
    "ŒîW ‚âà (U √ó V^T) √ó scale\n",
    "#      ^   ^\n",
    "#      |   ‚îî‚îÄ 16√ó8000 = 128K params\n",
    "#      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 8000√ó16 = 128K params\n",
    "#        Total: 256K params (0.4% of 64M!)\n",
    "\n",
    "# Why does this work?\n",
    "# The update needed during fine-tuning has LOW RANK\n",
    "# You can represent it with small matrices!\n",
    "# Similar to PCA - most variance in few dimensions\n",
    "```\n",
    "\n",
    "### Visual:\n",
    "```\n",
    "Original weight matrix (8000√ó8000):\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ                         ‚îÇ\n",
    "‚îÇ   64M parameters        ‚îÇ\n",
    "‚îÇ   (Don't update)        ‚îÇ\n",
    "‚îÇ                         ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "LoRA adapter (8000√ó16 + 16√ó8000):\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ 128K     ‚îÇ  √ó  ‚îÇ 128K     ‚îÇ  = 256K params to train\n",
    "‚îÇ params   ‚îÇ     ‚îÇ params   ‚îÇ    (Update these!)\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "\n",
    "Result:\n",
    "output = W√óinput + (U √ó V^T √ó scale √ó input)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Different Types of Fine-Tuning\n",
    "\n",
    "### Full Fine-Tuning:\n",
    "```\n",
    "Train all 8B parameters\n",
    "Pros: Best quality, most flexible\n",
    "Cons: Slow (days), expensive (100+ GB RAM), requires powerful GPU\n",
    "When: Large datasets (100K+), unlimited budget\n",
    "```\n",
    "\n",
    "### LoRA Fine-Tuning:\n",
    "```\n",
    "Train only ~42M parameters (0.5%)\n",
    "Pros: 2x faster, 60% less memory, good quality\n",
    "Cons: Slightly lower quality than full fine-tuning\n",
    "When: Most practical applications, limited resources\n",
    "```\n",
    "\n",
    "### QLoRA Fine-Tuning:\n",
    "```\n",
    "LoRA + 4-bit quantization\n",
    "Pros: 8x less memory, still good quality\n",
    "Cons: Slower than LoRA alone\n",
    "When: Very limited memory (< 12 GB GPU)\n",
    "```\n",
    "\n",
    "### Prompt Tuning:\n",
    "```\n",
    "Learn only the prompt prefix (a few tokens)\n",
    "Pros: Extremely fast, minimal memory\n",
    "Cons: Limited expressiveness, lower quality\n",
    "When: Quick experiments, multi-task learning\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be68c98",
   "metadata": {},
   "source": [
    "# Part 10: After Training - What's Next?\n",
    "\n",
    "## üíæ Saving Your Model\n",
    "\n",
    "### Two Options:\n",
    "\n",
    "### Option 1: Save LoRA Adapters (Recommended)\n",
    "```python\n",
    "model.save_pretrained(\"./lora_adapters\")\n",
    "# Saves: ~50-100 MB\n",
    "# What it contains:\n",
    "# - adapter_config.json (LoRA configuration)\n",
    "# - adapter_model.bin (LoRA weights)\n",
    "# - tokenizer.model (vocabulary)\n",
    "\n",
    "# To use later:\n",
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(\n",
    "    \"unsloth/llama-3.1-8b-Instruct-bnb-4bit\",\n",
    "    \"./lora_adapters\"\n",
    ")\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- Tiny file size (perfect for sharing)\n",
    "- Easy to switch between different LoRA adapters\n",
    "- Fast to load\n",
    "\n",
    "**Cons:**\n",
    "- Need base model at inference time\n",
    "- Not standalone\n",
    "\n",
    "### Option 2: Save Merged Model\n",
    "```python\n",
    "model.save_pretrained_merged(\n",
    "    \"./merged_model\",\n",
    "    tokenizer\n",
    ")\n",
    "# Saves: ~16 GB (full model size)\n",
    "\n",
    "# To use later:\n",
    "from transformers import AutoModelForCausalLM\n",
    "model = AutoModelForCausalLM.from_pretrained(\"./merged_model\")\n",
    "```\n",
    "\n",
    "**Pros:**\n",
    "- Standalone model (no base model needed)\n",
    "- Ready for deployment\n",
    "- Can upload to Hugging Face directly\n",
    "\n",
    "**Cons:**\n",
    "- Large file size (impractical for many scenarios)\n",
    "- Takes time to save/load\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Using Your Fine-Tuned Model\n",
    "\n",
    "### Inference (Making Predictions):\n",
    "```python\n",
    "# Prepare model for inference\n",
    "from unsloth import FastLanguageModel\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Create prompt\n",
    "prompt = \"\"\"Question: How to register a business in Nigeria?\n",
    "Answer: \"\"\"\n",
    "\n",
    "# Generate response\n",
    "inputs = tokenizer(\n",
    "    prompt,\n",
    "    return_tensors=\"pt\"\n",
    ").to(model.device)\n",
    "\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,  # Generate up to 512 tokens\n",
    "    temperature=0.7,      # Randomness (0=deterministic, 1=very random)\n",
    "    top_p=0.9,           # Nucleus sampling (keep top 90% probability)\n",
    "    do_sample=True       # Use sampling instead of greedy\n",
    ")\n",
    "\n",
    "response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "### Generation Parameters Explained:\n",
    "```python\n",
    "max_new_tokens=512\n",
    "  # Maximum tokens to generate\n",
    "  # Longer = slower but more complete responses\n",
    "  # Shorter = faster but truncated\n",
    "\n",
    "temperature=0.7\n",
    "  # Controls randomness (0-1)\n",
    "  # 0.0 = Always pick highest probability (deterministic)\n",
    "  # 0.7 = Medium randomness (balanced)\n",
    "  # 1.0+ = Very random (creative but potentially nonsensical)\n",
    "\n",
    "top_p=0.9\n",
    "  # Nucleus sampling: only consider top 90% probability tokens\n",
    "  # Lower = more focused, coherent responses\n",
    "  # Higher = more diverse, sometimes strange responses\n",
    "\n",
    "top_k=50\n",
    "  # Only consider top 50 most likely tokens\n",
    "  # Prevents very unlikely token selection\n",
    "\n",
    "do_sample=True\n",
    "  # Use sampling instead of greedy decoding\n",
    "  # True = More natural, varied responses\n",
    "  # False = More deterministic, repetitive\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üåê Deploying to Hugging Face Hub\n",
    "\n",
    "### Why upload?\n",
    "```\n",
    "‚úÖ Share with others\n",
    "‚úÖ Permanent storage\n",
    "‚úÖ Easy integration with other projects\n",
    "‚úÖ Version control for models\n",
    "```\n",
    "\n",
    "### Steps:\n",
    "```python\n",
    "# 1. Install and login\n",
    "from huggingface_hub import login\n",
    "login()  # Paste your HF token\n",
    "\n",
    "# 2. Upload LoRA adapters\n",
    "model.push_to_hub(\n",
    "    \"your_username/model_name\",\n",
    "    private=False  # True = only you can access\n",
    ")\n",
    "tokenizer.push_to_hub(\"your_username/model_name\")\n",
    "\n",
    "# 3. Now anyone can load:\n",
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(\n",
    "    \"unsloth/llama-3.1-8b-Instruct-bnb-4bit\",\n",
    "    \"your_username/model_name\"\n",
    ")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa6a16d",
   "metadata": {},
   "source": [
    "# Part 11: Summary & Quick Reference\n",
    "\n",
    "## üìã Key Concepts at a Glance\n",
    "\n",
    "| Concept | Simple Explanation | When Important |\n",
    "|---------|-------------------|----------------|\n",
    "| **Pre-training** | Model learns from internet data | Foundation for fine-tuning |\n",
    "| **Fine-tuning** | Specialize model for your domain | Main goal |\n",
    "| **LoRA** | Train only 0.5% parameters | Saves time and memory |\n",
    "| **Quantization** | Use smaller numbers (4-bit) | Reduces memory usage |\n",
    "| **Tokenization** | Convert text to numbers | Model input format |\n",
    "| **Batch Size** | Examples per update | Memory vs speed trade-off |\n",
    "| **Learning Rate** | Step size for updates | Controls convergence |\n",
    "| **Warmup** | Gradually increase LR | Stabilizes training |\n",
    "| **Overfitting** | Model memorizes training data | Check with validation set |\n",
    "| **ROUGE** | Measure response quality | Evaluate after training |\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Best Practices\n",
    "\n",
    "### Before Training:\n",
    "- ‚úÖ Prepare 500-5000 high-quality Q&A pairs\n",
    "- ‚úÖ Verify data format (question-answer JSON)\n",
    "- ‚úÖ Check GPU memory with `nvidia-smi`\n",
    "- ‚úÖ Start with smaller batch sizes if unsure\n",
    "\n",
    "### During Training:\n",
    "- ‚úÖ Monitor training/validation loss graphs\n",
    "- ‚úÖ Watch for divergence (loss increasing)\n",
    "- ‚úÖ Check validation loss to catch overfitting\n",
    "- ‚úÖ Save checkpoints periodically\n",
    "\n",
    "### After Training:\n",
    "- ‚úÖ Evaluate on test set (never seen during training)\n",
    "- ‚úÖ Manual evaluation of sample responses\n",
    "- ‚úÖ Calculate ROUGE scores\n",
    "- ‚úÖ Compare to baseline model\n",
    "- ‚úÖ Save both LoRA adapters and merged model\n",
    "\n",
    "---\n",
    "\n",
    "## üö® Common Mistakes to Avoid\n",
    "\n",
    "```\n",
    "‚ùå Using same data for train AND validation\n",
    "   ‚Üí You can't detect overfitting!\n",
    "   ‚úÖ Always keep test data separate\n",
    "\n",
    "‚ùå Training for only 10 steps\n",
    "   ‚Üí Model hasn't learned much\n",
    "   ‚úÖ Minimum 60 steps, better with 500+\n",
    "\n",
    "‚ùå Setting learning rate to 0.1\n",
    "   ‚Üí Training will diverge immediately\n",
    "   ‚úÖ Use 2e-4 to 5e-4 for fine-tuning\n",
    "\n",
    "‚ùå Ignoring out-of-memory errors\n",
    "   ‚Üí Training will crash\n",
    "   ‚úÖ Reduce batch size or max_seq_length\n",
    "\n",
    "‚ùå Not saving model checkpoints\n",
    "   ‚Üí If training crashes, lose everything\n",
    "   ‚úÖ Save model every 100 steps\n",
    "\n",
    "‚ùå Using low-quality training data\n",
    "   ‚Üí Model learns garbage\n",
    "   ‚úÖ Quality matters more than quantity\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä Expected Results\n",
    "\n",
    "### Training Loss Progression (for 60 steps):\n",
    "```\n",
    "Step 1:   Loss = 2.5  (random model)\n",
    "Step 10:  Loss = 1.8  (20% improvement)\n",
    "Step 30:  Loss = 0.8  (65% improvement)\n",
    "Step 60:  Loss = 0.4  (84% improvement)\n",
    "\n",
    "This is normal! Loss improvement is logarithmic.\n",
    "```\n",
    "\n",
    "### Expected ROUGE Scores (after 60 steps):\n",
    "```\n",
    "Small dataset (100 examples):  ROUGE-1 ‚âà 0.25-0.35\n",
    "Medium dataset (1000 examples): ROUGE-1 ‚âà 0.35-0.50\n",
    "Large dataset (10K examples):   ROUGE-1 ‚âà 0.50-0.65\n",
    "\n",
    "Note: These are just benchmarks, actual results depend on data quality\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üîß Hyperparameter Tuning Guide\n",
    "\n",
    "### If training is too slow:\n",
    "```\n",
    "1. Reduce MAX_SEQ_LENGTH (1024 ‚Üí 512)\n",
    "2. Increase PER_DEVICE_BATCH_SIZE (2 ‚Üí 4)\n",
    "3. Reduce LORA_R (16 ‚Üí 8)\n",
    "4. Increase GRADIENT_ACCUMULATION_STEPS (4 ‚Üí 1)\n",
    "```\n",
    "\n",
    "### If model quality is poor:\n",
    "```\n",
    "1. Increase training data (more examples)\n",
    "2. Increase MAX_STEPS (60 ‚Üí 500)\n",
    "3. Increase LORA_R (8 ‚Üí 32)\n",
    "4. Reduce LEARNING_RATE (2e-4 ‚Üí 5e-5)\n",
    "5. Increase WARMUP_STEPS (5 ‚Üí 50)\n",
    "```\n",
    "\n",
    "### If out of memory:\n",
    "```\n",
    "1. Reduce PER_DEVICE_BATCH_SIZE (2 ‚Üí 1)\n",
    "2. Increase GRADIENT_ACCUMULATION_STEPS (4 ‚Üí 8)\n",
    "3. Reduce MAX_SEQ_LENGTH (1024 ‚Üí 512)\n",
    "4. Reduce LORA_R (16 ‚Üí 8)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3343243c",
   "metadata": {},
   "source": [
    "# üéì Conclusion\n",
    "\n",
    "## You now understand:\n",
    "\n",
    "‚úÖ **What** fine-tuning is and why it's useful\n",
    "\n",
    "‚úÖ **Why** LoRA makes it practical\n",
    "\n",
    "‚úÖ **How** tokenization works\n",
    "\n",
    "‚úÖ **What** each hyperparameter controls\n",
    "\n",
    "‚úÖ **How** the training process works step-by-step\n",
    "\n",
    "‚úÖ **Why** we split data into train/validation/test\n",
    "\n",
    "‚úÖ **How** to evaluate your model\n",
    "\n",
    "‚úÖ **What** common issues to watch for\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps:\n",
    "\n",
    "1. **Prepare your data**: Collect 500-5000 high-quality Q&A pairs\n",
    "2. **Run the original notebook**: Use the accompanying `sft_finetuning.ipynb`\n",
    "3. **Experiment**: Try different hyperparameters and see the effects\n",
    "4. **Evaluate**: Test your model on held-out examples\n",
    "5. **Deploy**: Share your model with others or integrate into applications\n",
    "\n",
    "---\n",
    "\n",
    "## Helpful Resources:\n",
    "\n",
    "- **Hugging Face Documentation**: https://huggingface.co/docs\n",
    "- **Unsloth GitHub**: https://github.com/unslothai/unsloth\n",
    "- **PEFT (Parameter-Efficient Fine-Tuning)**: https://github.com/huggingface/peft\n",
    "- **Llama 3 Model Card**: https://huggingface.co/meta-llama/Llama-3-8b\n",
    "\n",
    "---\n",
    "\n",
    "## Good luck with your fine-tuning! üöÄ\n",
    "\n",
    "Remember: The key to good results is:\n",
    "1. **High-quality data** (more important than fancy hyperparameters)\n",
    "2. **Proper evaluation** (understand how well your model really performs)\n",
    "3. **Patience with experimentation** (small changes can have big effects)\n",
    "4. **Reading error messages** (they usually tell you exactly what's wrong)\n",
    "\n",
    "Happy fine-tuning! üéâ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a_finetuned",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
